---
pagetitle: "Data Wrangling"
editor: source
format: 
  revealjs:
    chalkboard: true
    incremental: true
    theme: [default, custom.scss]
    height: 900
    width: 1600
    slide-number: c
    auto-stretch: false
    callout-appearance: simple
    pdf-max-pages-per-slide: 2
    menu: 
      side: right
      numbers: true
execute:
  echo: true
  warning: false
  message: false
---

```{r}
#| include: false
#| warning: false
#| message: false

knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, 
                      fig.retina = 3, fig.align = 'center')
library(knitr)
library(ggplot2)
library(dplyr)
```

::::: columns
::: {.column .center width="60%"}
![](img/DAW.jpeg){width="90%"}
:::

::: {.column .center width="40%"}
<br>

[Data Wrangling]{.custom-title}

<br> <br> 

[Megan Ayers]{.custom-subtitle}

[Math 141 \| Spring 2026 <br> Wednesday, Week 2]{.custom-subtitle}
:::
:::::

------------------------------------------------------------------------

## Goals For Today
-   Briefly discuss packages and the difference between base R and `dplyr`
-   Learn to wrangle data, mainly with `dplyr`

------------------------------------------------------------------------

## Packages

::::: columns
::: {.column .center width="75%"}
- "Base R": core set of built-in functions in R - no extra install required
- R is free and open source - many have contributed **packages**, like `ggplot2`, to make certain things easier to do 
- `dplyr`: part of a collection of data science packages called the `tidyverse`
:::

::: {.column .center width="25%"}
![](img/dplyr.png){fig-align="right"}
:::
:::::


------------------------------------------------------------------------

## Base R vs `dplyr`

- Throughout the course, we will use base `R` and `dplyr` for different tasks.
- We'll try to be consistent with when we use what, but be aware that there are multiple ways to accomplish most tasks.
- Beyond this class as you work with `R`, I highly recommend developing skills using both base `R` and `dplyr`. Each has its strengths, both are widely used.


------------------------------------------------------------------------

## Data for today

```{r}
dogs <- read.csv("https://data.cambridgema.gov/api/views/sckh-3xyx/rows.csv")

# Useful wrangling that we will come back to
dogs <- dogs[, c("Dog_Name", "Dog_Breed", "Neighborhood")]

dogs_top5 <- dogs %>%
  mutate(Dog_Breed = case_when(Dog_Breed == "Mixed Breed" ~ "Mixed",
                               TRUE ~ "Single")) %>%
  filter(Dog_Name %in% c("Luna", "Charlie", "Lucy", "Cooper", "Rosie"))

```

## Data for today

```{r}
str(dogs)

str(dogs_top5)
```


------------------------------------------------------------------------

### Data Wrangling: Transformations done on the data

**Why wrangle the data?**

::::: columns
::: {.column .fragment width="50%"}
To **summarize** the data.
:::

::: {.column .fragment width="50%"}
→ To compute the mean and standard deviation of miles ridden by bikeshare users.
:::
:::::

::::: columns
::: {.column .fragment width="50%"}
To **drop** missing values. (Need to be careful here!)
:::

::: {.column .fragment width="50%"}
→ In our Lab 2, we'll see that `ggplot2` will often drop observations before creating a graph.
:::
:::::

::::: columns
::: {.column .fragment width="50%"}
To **filter** to a particular subset of the data.
:::

::: {.column .fragment width="50%"}
→ To subset the `pdxTrees` data to just a few species types.
:::
:::::

::::: columns
::: {.column .fragment width="50%"}
To **collapse** the categories of a categorical variable.
:::

::: {.column .fragment width="50%"}
→ To go from 86 dog breeds to just mixed or single breed.
:::
:::::

------------------------------------------------------------------------

### Data Wrangling: Transformations done on the data

**Why wrangle the data?**

::::: columns
::: {.column .fragment width="50%"}
To **arrange** the data to make it easier to display.
:::

::: {.column .fragment width="50%"}
→ To sort from most common dog name to least common.
:::
:::::

::::: columns
::: {.column .fragment width="50%"}
To fix how `R` **stores** a variable (or make a new one).
:::

::: {.column .fragment width="50%"}
→ Converting quantitative variables to/from categorical variables
:::
:::::

------------------------------------------------------------------------

## `dplyr` for Data Wrangling

-   Five common wrangling verbs:
    - `count()`
    - `filter()`
    - `arrange()`
    - `mutate()`
    - `summarize()` 
-   One action:
    - `group_by()`

------------------------------------------------------------------------

## Motivation for "filtering"

```{r}
count(dogs, Dog_Name)
```

------------------------------------------------------------------------

## Filtering cases

We remove rows according to logical conditions about variable cases:

::::: columns
::: {.column width=50%}
::: {.fragment}
```{r}
freddy <- filter(dogs, Dog_Name == "Freddy")
freddy
```
:::

<br>

::: {.fragment}

```{r}
not_freddy <- filter(dogs, Dog_Name != "Freddy")
head(not_freddy)
```
:::
:::

::: {.column width=50% .fragment}
![](img/freddie.jpeg){width=50%}
:::
:::::

------------------------------------------------------------------------

## Filtering cases

::: {.fragment}
We remove rows according to logical conditions about variable cases:

```{r}
filter(dogs, Dog_Name %in% c("Freddy", "Bo"))
```
:::

<br>

::: {.fragment}
```{r}
filter(dogs, Dog_Name == "Freddy" | Dog_Name == "Bo")
```
:::

<br>

::: {.fragment}
```{r}
filter(dogs, Dog_Name == "Rosie" & Dog_Breed == "Goldendoodle")
```
:::

------------------------------------------------------------------------

## The pipe: `%>%`

::: {.fragment}
The pipe operator `%>%` is a handy way to string multiple commands together in `dplyr`. Instead of:

```{r}
not_freddy <- filter(dogs, Dog_Name != "Freddy")
head(not_freddy)
```
:::

<br>

::: {.fragment}
... we can write:
```{r}
dogs %>% filter(Dog_Name != "Freddy") %>% head()
```
:::

------------------------------------------------------------------------


## Extracting variables 

We can use `$` to extract a single variable

```{r}
dogs_top5$Dog_Name
```

<br>

To extract multiple variables, can use syntax like `df[, c("var1", "var2")]`. 

```{r}
head(dogs_top5[, c("Dog_Name", "Dog_Breed")])
```


------------------------------------------------------------------------

## FYI: We can filter cases with syntax like `df[condition, ]`

Rows and columns can be subset at the same time: 

`df[(rows to extract), (columns to extract)]`.

<br>

In this class we will rarely use this syntax, but it is common in the wild. 

<br>

```{r}
keep_names <- c("Maggie", "Stella")
dogs[dogs$Dog_Name %in% keep_names, c("Dog_Name", "Dog_Breed")]
```

------------------------------------------------------------------------

## Arranging cases

<br>

Use `arrange()` to change the order of cases in a data frame
```{r}
dogs_top5 %>%
  arrange(Dog_Name)
```


------------------------------------------------------------------------

## Creating a **new variable**

We use `mutate()` to create new variables

```{r}
head(dogs_top5)
```

```{r}
dogs_top5 %>%
  mutate(animal = "dog",
         Dog_Name = toupper(Dog_Name)) %>% 
  head()
```



------------------------------------------------------------------------


## New Data Setting: [Bureau of Labor Statistics (BLS) Consumer Expenditure Survey](https://www.bls.gov/cex/) {.smaller}

**BLS Mission**: "Measures labor market activity, working conditions, price changes, and productivity in the U.S. economy to support public and private decision making."

**Data**: Last quarter of the 2016 BLS Consumer Expenditure Survey.

```{r}
ce_raw <- read.csv("data/fmli.csv", na = c("NA", "."))
str(ce_raw)
```

------------------------------------------------------------------------

## Wrangling CE Data {.smaller}

::::::: columns
:::: {.column width="\"50%"}
Want to better understand a family's income and expenditures

```{r}
ce <- ce_raw[, c("NEWID", "PRINEARN", "FINCBTAX", "BLS_URBN",
                 "HIGH_EDU", "TOTEXPCQ", "IRAX")]
dim(ce)
```

**Variables:**

::: nonincremental
-   `NEWID`: ID for the household
-   `PRINEARN`: ID for which member of the household is the principal earner
-   `FINCBTAX`: Final income before taxes for the year
:::
::::

:::: {.column width="\"50%"}
::: nonincremental
-   `BLS_URBN`: 1 = urban, 2 = rural
-   `HIGH_EDU`: Highest education in the household. 00 = Never attended, 10 = Grades 1-8, 11 = Grades 9-12, no degree, 12 = High school graduate, 13 = Some college, no degree, 14 = Associates degree, 15 = Bachelor's degree, 16 = Masters, Professional/doctorate degree
-   `TOTEXPCQ` = Total household expenditures for the current quarter
-   `IRAX` = Total in retirement funds
:::
::::
:::::::

------------------------------------------------------------------------

## Wrangling CE Data

```{r}
ce <- ce %>%
  mutate(YEARLY_EXP = TOTEXPCQ*4)
ce
```

------------------------------------------------------------------------

## Using logical operators

```{r}
ce_sub <- ce %>%
  filter(YEARLY_EXP > 0, BLS_URBN == 1, HIGH_EDU != "00")
ce_sub
```

------------------------------------------------------------------------

## Using logical operators

```{r}
ce_sub <- ce %>%
  filter(YEARLY_EXP > 0, (BLS_URBN == 1 | HIGH_EDU != "00"))
ce_sub
```

<br>

Which version leaves more cases in the data frame? 

------------------------------------------------------------------------

## Recoding Variables with `case_when()`

```{r}
count(ce, BLS_URBN)
```


<br>

::: {.fragment}
```{r}
ce <- ce %>%
  mutate(BLS_URBN = case_when(BLS_URBN == 1 ~ "Urban",
                              TRUE ~ "Rural"))
count(ce, BLS_URBN)

```
:::


------------------------------------------------------------------------

## Creating Variables with `case_when()`

```{r}
ce %>% 
  mutate(HIGH_EDU = as.numeric(HIGH_EDU)) %>%
  count(HIGH_EDU)
```


<br>

::: {.fragment}
```{r}

ce <- ce %>% 
  mutate(HIGH_EDU2 = case_when(HIGH_EDU <= 11 ~ "Less than high school degree",
                               HIGH_EDU <= 13 ~ "High school degree",
                               HIGH_EDU >= 14 ~ "College degree",
                               TRUE ~ NA))

count(ce, HIGH_EDU2)

```
:::


------------------------------------------------------------------------

## Variable Names

Sometimes datasets come with terrible variable names.

```{r}
names(ce)
```

<br>

::: {.fragment}
We can fix that with `rename()`.
```{r}
ce <- ce %>%
  rename(INCOME = FINCBTAX)
```
:::


------------------------------------------------------------------------

## Handling Missing Data

Want to compute mean income and mean retirement funds.

::::: columns
::: {.column width="\"50%"}
```{r}
mean(ce$INCOME)
```
<br>
```{r}
mean(ce$IRAX)
```
:::

::: {.column .fragment width="\"50%"}
```{r}
ce_aggressive <- na.omit(ce_raw)
ce_aggressive
```
:::
:::::

------------------------------------------------------------------------

## Handling Missing Data

```{r}

ce_moderate <- ce %>%
  filter(!is.na(IRAX), !is.na(INCOME))

mean(ce_moderate$INCOME)

mean(ce_moderate$IRAX)

```

<br>

::: {.fragment}
Or, to be very conservative about preserving data:
```{r}
mean(ce$INCOME, na.rm = TRUE)
mean(ce$IRAX, na.rm = TRUE)
```
:::

<br>

::: fragment
**Q:** Why does the mean income value change between these approaches, even though there are no NA income values?
:::

::: fragment
**A:** The moderate approach still drops rows with non-NA `INCOME` values
:::

------------------------------------------------------------------------

## Summarizing within groups using `group_by()` and `summarize()`

```{r}
ce_moderate %>%
  group_by(BLS_URBN) %>%
  summarize(mean_IRAX = mean(IRAX))
```

<br>

::: {.fragment}
```{r}
ce_moderate %>%
  group_by(BLS_URBN, HIGH_EDU2) %>%
  summarize(mean_IRAX = mean(IRAX))
```
:::

------------------------------------------------------------------------

## Naming Wrangled Data

When I make a new data frame, what name should I give it? Importantly, should I **write over my original dataframe** or should I **save a new dataframe**?

-   Advice:
    -   Is your new data frame structurally different? If so, give it a **new name**.
    -   Are you removing values you will need for a future analysis within the same document? If so, give it a **new name**.
    -   Are you just adding to or cleaning the data? If so, then **write over** the original.

------------------------------------------------------------------------

### Sage Advice from ModernDive

<br>

> "Crucial: Unless you are very confident in what you are doing, it is worthwhile not starting to code right away. Rather, first sketch out on paper all the necessary data wrangling steps not using exact code, but rather high-level pseudocode that is informal yet detailed enough to articulate what you are doing. This way you won't confuse what you are trying to do (the algorithm) with how you are going to do it [(writing code)]."


------------------------------------------------------------------------

## In-Class Exercise: Data wrangling pseudocode

Anonymized data from a 2017 study on the effect of the higher education system on upward mobility [(Chetty et al. 2017)](http://www.equality-of-opportunity.org/data/).

<br>

::::: columns
::: {.nonincremental .column width="50%"}
-   `region`: `1` for Northeast, `2` for Midwest, `3` for South, and `4` for West
-   `state`:  State name
-   `tier_name`: Tier defined by selectivity and type
-   `mr_kq5_pq1`: Mobility rate, top 20% of the income distribution.
:::

::: {.column width="50%"}
```{r}
load("data/colleges.Rdata")
head(colleges[, c("region", "state", "tier_name", "mr_kq5_pq1")])
```
:::
:::::

<br>

::: {.fragment}
**In groups of 3-4, on paper, write pseudocode to answer**: what states in the west have the highest average mobility rate across their private and elite colleges? 
:::


```{r include=FALSE, eval=FALSE}
load("data/colleges.Rdata")

# For "selective private" or "elite" schools in the west, which western state has the highest average  mobility rate (top 1\% of the income distribution) amongst selective private/elite schools? 

colleges %>%
  filter(tier_name %in% c("Selective private", "Other elite schools (private and public)"),
         region == 4) %>%
  group_by(state) %>%
  summarize(mean_mr = mean(mr_kq5_pq1)) %>%
  arrange(-mean_mr)

```

